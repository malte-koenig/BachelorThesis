{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this file I create WordClouds for every Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') #once\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Lyrics from each Genre, initialize Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyrical dataset enriched with meta data created in 'enriched_metadata.ipynb' \n",
    "songs = pd.read_csv(\"songs_enriched.csv\", sep=\",\", engine=\"python\", encoding='utf-8')\n",
    "\n",
    "hiphop = songs.loc[songs['genre'].str.contains('Hip Hop')]\n",
    "pop = songs.loc[songs['genre'].str.contains('Pop')]\n",
    "rock = songs.loc[songs['genre'].str.contains('Rock')]\n",
    "country = songs.loc[songs['genre'].str.contains('Country')]\n",
    "\n",
    "hiphop_lyrics = hiphop['a_lyrics'].values.tolist()\n",
    "rock_lyrics = rock['a_lyrics'].values.tolist()\n",
    "pop_lyrics = pop['a_lyrics'].values.tolist()\n",
    "country_lyrics = country['a_lyrics'].values.tolist()\n",
    "\n",
    "# tokenize and remove punctuations\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "stop_words = STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WordClouds\n",
    "### Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(rock_lyrics))\n",
    "\n",
    "s = \"\"\n",
    "for l in data_words:\n",
    "    s = s + ','.join(l)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(stopwords=stop_words, width=1280, height=720, min_font_size=15, \n",
    "                      max_font_size=160, background_color=\"white\", max_words=2000, \n",
    "                      contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(s)# Visualize the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(pop_lyrics))\n",
    "\n",
    "s = \"\"\n",
    "for l in data_words:\n",
    "    s = s + ','.join(l)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(stopwords=stop_words, width=1280, height=720, min_font_size=15, \n",
    "                      max_font_size=160, background_color=\"white\", max_words=2000, \n",
    "                      contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(s)# Visualize the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hip hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(hiphop_lyrics))\n",
    "\n",
    "s = \"\"\n",
    "for l in data_words:\n",
    "    s = s + ','.join(l)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(stopwords=stop_words, width=1280, height=720, min_font_size=15, \n",
    "                      max_font_size=160, background_color=\"white\", max_words=2000, \n",
    "                      contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(s)# Visualize the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(country_lyrics))\n",
    "\n",
    "s = \"\"\n",
    "for l in data_words:\n",
    "    s = s + ','.join(l)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(stopwords=stop_words, width=1280, height=720, min_font_size=15, \n",
    "                      max_font_size=160, background_color=\"white\", max_words=2000, \n",
    "                      contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(s)# Visualize the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
